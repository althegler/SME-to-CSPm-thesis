The Internet of Things, computerised medical implants, and the omnipresent growth in robotics, bring with them an increased demand for programmers, that are able to develop software for these devices. While this observation may not in itself appear to present a new challenge, many other areas have previously presented a need for more programmers. The new challenge is that these new growth areas are all focused on small size, low power consumption, and high reliability. This means that traditional software engineering methods, and thus traditionally trained programmers, are often not sufficiently qualified to work with these technologies.
In previous decades, such systems have been developed by electronic engineers that apply far more rigid development approaches. Especially for hardware solutions like Very-Large-Scale Integration (VLSI) and Field-Programmable Gate Array (FPGA), correctness has always been favored over productivity due to a more rigid environment, than traditional software developers are used to.
While tools have obviously improved and methods refined, the VLSI process is still mostly the same as presented in~\cite{Agrawal:1985:VDP:320599.322570}. The primary workflow from~\cite{Agrawal:1985:VDP:320599.322570} is shown in Figure~\ref{fig:Agrawal}; note the focus on verification in each step.
\begin{figure}[!ht]
  \centering
  \begin{tikzpicture}[auto, scale=0.8, every node/.style={scale=0.8}]
    \node[myrectangle] (synthesis)                            {Synthesis and test generation};
    \node[myrectangle] (layout)    [right=2.5cm of synthesis] {Layout};
    \node[myrectangle] (wafer)     [right=2.5cm of layout]    {Wafer\\fabrication and packaging};

    \node[myrectangle] (verification1) [below=0.5cm of synthesis] {Verification};
    \node[myrectangle] (verification2) [below=0.5cm of layout]    {Verification};
    \node[myrectangle] (verification3) [below=0.5cm of wafer]     {Testing};

    \node (input) [left=1.5cm of synthesis] {};
    \draw[myarrow] (input) -- node[near start] {\scriptsize Requirements} (synthesis);

    \node (output) [right=1.5cm of wafer] {};
    \draw[myarrow] (wafer) -- node[near end] {\scriptsize VLSI devices} (output);

    \draw[myarrow] (synthesis) -- node[text width=2cm, align=center, midway] {\scriptsize Logic design and test data} (layout);
    \draw[myarrow] (layout)    -- node[text width=2cm, align=center, midway] {\scriptsize Mask and test data} (wafer);

    \draw[myarrow] (synthesis)     to[out=345, in=15]  (verification1);
    \draw[myarrow] (verification1) to[out=165, in=195] (synthesis);

    \draw[myarrow] (layout)        to[out=345, in=15]  (verification2);
    \draw[myarrow] (verification2) to[out=165, in=195] (layout);

    \draw[myarrow] (wafer)         to[out=345, in=15]  (verification3);
    \draw[myarrow] (verification3) to[out=165, in=195] (wafer);

    \draw[myarrow] (verification3) -- node[text width=3cm, align=center, midway, below=2mm] {\scriptsize Timing, testability, quality, reliability, and yield problems} (verification2);
    \draw[myarrow] (verification2) -- node[text width=3cm, align=center, midway, below=2mm] {\scriptsize Timing, testability, quality, reliability, and yield problems} (verification1);
  \end{tikzpicture}
  \caption{VLSI process workflow.}
  \label{fig:Agrawal}
\end{figure}

While the VLSI community is fundamentally following this 1980's design approach, more high-level tools and abstractions have been introduced. Philippe et al.~\cite{ coussy2009introduction} show a workflow (reproduced in Figure~\ref{fig:coussy}) where the important part is the verification, that has been partly automated by basing the development on a formal specification of the solution.

There is no denying that the subjectively slow and rigid development process in the VLSI world~\cite{kepner2004hpc} is highly successful in producing correct and reliable circuits. At the same time, conventional software development is highly focused on productivity and time-to-market, for example, smartphone applications are often developed for continuous release, where bug patches and new features are rolled out daily. This is of course not possible with hardware.

Thus, a growing chasm exists between the way most programmers are trained, and the competencies that are needed to support the growth in mission critical embedded devices.\\
\begin{figure}[!ht]
  \centering
  \begin{tikzpicture}[auto]
    \node[myrectangle, text width=3cm, minimum height=1cm, inner sep=5pt, inner ysep=5pt] (specification) {Specification};
    \node[myrectangle, text width=3cm, minimum height=1cm, inner sep=5pt, inner ysep=5pt] (compilation) [right=0.5cm of specification] {Compilation};
    \node[myrectangle, text width=3cm, minimum height=1cm, inner sep=5pt, inner ysep=5pt] (formalmodel) [right=0.5cm of compilation] {Formal model};

    \node[myrectangle, text width=3cm, minimum height=1cm, inner sep=5pt, inner ysep=5pt] (behavioral) [right=0.5cm of formalmodel] {Behavioral synthesis};

    \node[myrectangle, text width=3cm, minimum height=1cm, inner sep=5pt, inner ysep=5pt] (generation) [below=1cm of specification] {Generation};
    \node[myrectangle, text width=3cm, minimum height=1cm, inner sep=5pt, inner ysep=5pt] (rtl) [right=0.5cm of generation] {RTL architecture};
    \node[myrectangle, text width=3cm, minimum height=1cm, inner sep=5pt, inner ysep=5pt] (logic) [right=0.5cm of rtl] {Logic synthesis};

    \node[] (dotdotdot) [right=0.5cm of logic] {...};

    \draw[myarrow] (specification) -- (compilation);
    \draw[myarrow] (compilation) -- (formalmodel);
    \draw[myarrow] (formalmodel) -- (behavioral);

    \draw[myarrow] (behavioral) |-([shift={(0mm,-5mm)}]behavioral.south west) -- ([shift={(0mm,5mm)}]generation.north east)-| (generation);

    \draw[myarrow] (generation) -- (rtl);
    \draw[myarrow] (rtl) -- (logic);
    \draw[myarrow] (logic) -- (dotdotdot);
  \end{tikzpicture}
  \caption{Reproduced workflow from Philippe et al.~\cite{coussy2009introduction}.}
  \label{fig:coussy}
\end{figure}


In this thesis, I propose a tool to help bridge the gap between available programmer profiles and the required competencies for developing embedded devices. My approach is based on generating a specification from a software implementation and test-suite observations. The overarching goal is to reach a level where a conventional software programmer can write a solution in the new hardware design model, Synchronous Message Exchange (SME)~\cite{Vinter2014, Vinter2015, Skovhede}, and develop a conventional test suite in the software engineering tradition. SME will be further introduced in Chapter \ref{chap:background}. By combining this implementation with the \emph{observed} values of internal states in an SME based system implementation, we can produce a formal specification of the system, which will be introduced further in Chapter \ref{chap:background}.
This specification can be fed into a formal verification tool and thus improve the correctness guarantees from what is covered by the individual test vectors to the entire space that is spawned by the set of test vectors.\\

We approach the task by transpiling\footnote{Source-to-source compile.} the new SME Implementation Language (SMEIL)~\cite{smeil} for SME into \cspm{}~\cite{Scattergood1998} and verify the formal properties of this version with a tool like FDR4~\cite{fdr}.
\section{Motivation}
As explained, hardware testing is not as simple and reusable as software testing ,and it is not possible to deploy automatic bug patches for physical hardware. Therefore, it is cheaper for the hardware companies to have their newly developed hardware model tested as extensively as possible before production, than shipping physical hardware with a critical error. Although the testing can be extensive, it is difficult to achieve complete code coverage accounting for all corner cases using hand written test cases. There are several examples throughout history where more verification could have saved both lives and resources.
\subsection{Ariane 501 failure}
The Ariane 5 lifting rocket\cite{InquiryBoard1996} was designed to launch large payloads into Earth orbit, such as communications satellites, etc. It was owned by the European Space Agency (ESA) and the French space agency Centre National d'\'Etudes Spatiales (CNES), and manufactured by Airbus Defence and Space.\\

Ariane 5 was the follow-up to the successful Ariane 4 launchers. On June 4th, 1996, the Ariane 5 rocket was first flight tested. At about 30 seconds after successful lift-off, the rocket exploded midair, resulting in an approximately \$500 million loss for ESA and CNES. The failure could have been avoided, if there had been more focus on verification or simulation within the systems of Ariane 5. Luckily the rocket was unmanned, but this type of failure could happen in any other critical system. This launch failure is acknowledged as one of the most expensive human errors in history. \\

The failure of Ariane 5 was partially caused by a bug in the Inertial Reference System (SRI) that measures the attitude of the launcher and its movements in space. The SRI comprises an internal computer which calculates angles and velocities.
The failure occurred due to an unexpected high value of an internal alignment function result called Horizontal Bias (BH). The BH value is related to the horizontal velocity and was represented as a 64-bit floating point number. This value was converted to a 16-bit signed integer within the SRI and sent to the On-Board Computer (OBC), which controls the direction of the nozzles of the solid boosters.\\

The BH value had also been calculated in the Ariane 4 systems, so it was not thought of as insecure. However, because the trajectory of Ariane 5 was considerably different than that of Ariane 4, this value was much higher. Due to this high BH value, the 64-bit floating point number could not be represented by a 16-bit signed integer, so the conversion caused an overflow.
The result of the overflow was interpreted as actual flight data by the OBC and according to this misinterpreted flight data, the rocket was off course. The OBC counteracted what it thought was a wrong angle of the rocket by turning the nozzles to change course. Within a few seconds, the forces of aerodynamics ripped the solid boosters apart from the core stage. This caused the self-destruct mechanism to trigger, and the rocket self-destructed in a giant explosion shortly afterwards. The backup SRI, that should take over when errors occur in the active SRI, was executing the same code as the active SRI and had failed, for the same reasons, just before the active SRI.\\

On the Ariane 4 rocket, the BH value was necessary for a short while after lift-off, but this had been changed in the Ariane 5 where the data was only crucial to the rocket at lift-off. Afterwards, the data should not have had any influence on the rocket. but unfortunately, it had not been predicted that the conversion could overflow and so the functionality of the BH value had been kept. If this functionality and the consequences of a different trajectory had been properly considered for the Ariane 5 rocket, this failure might have been avoided.
\subsection{Therac-25 failure}
In the 80's the company Atomic Energy of Canada Limited (AECL) manufactured a revolutionary radiation therapy machine, the Therac-25\cite{Leveson1993}, which could provide two different kinds of radiation treatment. At that time, hospitals would typically have two different machines to be able to perform both of the treatments that a single Therac-25 machine could perform.\\
Radiation is used to kill cancer cells and so a patient is exposed to a beam of particles, or radiation, in specific doses that are designed to kill the specific type of cancer cells. Because cancer cells are more sensitive to radiation than normal cells, the radiation will kill the cancer cells but cause relatively minor damage to the normal tissue. However, radiation is damaging to normal tissue as well and it is, therefore, essential to specify the exact amount of radiation needed in a specific area to minimise the damage to the healthy cells.\\

The first type of treatment was a electron-beam treatment, which kills shallow tissue, like skin cancer. The second treatment option of the Therac-25 was a beam of higher-energy X-ray photons, which travels further into the tissue and are therefore better suited for cancer in deeper-lying tissue. \\

The Therac-25 was based on the previous Therac-20 and Therac-6, which had been very successful. The Therac-20 and Therac-6 both had hardware safety interlocks to avoid failures but unfortunately, this had been removed in the Therac-25 in favor of software-based security. AECL put more faith in software reliability than on hardware. \\

After the Therac-25 had been operational for a couple of years, a series of incidents happened, where patients were overexposed to radiation, leading to six cases of serious injury, resulting in death for some of them. Friz Hager, a physicist at East Texas Cancer Center, tested the Therac-25 rigorously to reproduce the errors they had experienced. He was able to demonstrate the error showing that if the user selected the X-Ray mode on the Therac-25, the machine began setting up for high-powered X-rays, which would take about 8 seconds. If the user switched to Electron-beam mode before the machine finished setting up for X-ray mode, i.e within 8 seconds, the turntable that controlled the amount of radiation, would not switch to the correct position causing an enormous amount of radiation to reach the patient.\\
After solving the problem and releasing a new version of the Therac-25, another problem emerged where a patient was overexposed. This time it turned out to be a counter overflow within the system and if a command was sent at the exact moment the counter overflowed, the machine would not set up properly, again resulting in an overexposure of radiation for the patient. \\
After this incident with the Therac-25, it was found that some of the same software problems were found in Therac-20, but due to the hardware precautions, the problems never occurred.
This example shows how important it is for critical systems to be well-designed, as well as well-tested or verified.

\subsection{The patriot missile failure}
During the Persian Gulf war, on February 25, 1991, an American Patriot missile failed to intercept an incoming Iraqi Scud missile, which caused the Scud to hit an American Army barracks injuring around 100 people and killing 28 soldiers~\cite{patriot1991}.\\

The Patriot missile failed due to an error in converting an integer, representing time since last boot, to a floating-point number using a 24-bit register. As time since last boot increased, the limited 24-bit register did not represent enough precision and so the chopping error increased. At the time of the incident, the Patriot missile battery had been on for approximately 100 hours, which caused the chopping inaccuracy to be around 0.34 seconds. The Scud travels at around 1.676 meters per second, and therefore in the 0.34 seconds, it travels more than a half kilometer. This caused the Patriot missile to wrongly predict the location of the Scud.
The inaccuracy of the 24-bit representation caused the Patriot missile to perform inaccurate calculations, and the consequence of this was that the Patriot missile missed its target Scud missile. This example shows how it is impossible to test 100\% of any system and how that can cause horrible failures. If the Patriot missile systems had been verified or had been subject to long-term testing, this accident might have been avoided. An example, similar to the Patriot missile failure, will be introduced in this thesis and will be verified to show potentiel failures.
%Intels-division bug \\
%Toyota bremse-fejl\\
\section{Learning goals}
The learning goals accepted for this thesis are:
\begin{itemize}
\item Reflect on the set of SME expressible problems, that are verifiable with FDR4.
\item Reason about efficient code transformation from an executable format to a verifiable format
\item Reason about design choices and their consequences for execution performance.
\item Demonstrate efficient constraint transfer from SME to FDR4.
\item Reason about SME program size and time to verification.
\item Reflect on the generality of a generic verification template.
\item Disseminate project results to a professional audience.
\end{itemize}


% \section{Limitations}


